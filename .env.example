LLM_BASE_URL="http://host.docker.internal" # for Ollama outside .devcontainer 
# LLM_BASE_URL="http://localhost" # for .devcontainer Ollama
# LLM_BASE_URL="https://api.openai.com" # for OpenAI
LLM_BASE_URL_PORT="11434" # Comment if using OpenAI
FRONTEND_URL="http://localhost:8080"
VITE_API_URL="http://localhost:8000"
# TEXT_MODEL="gpt-4o" # or "basic"
# OPENAI_API_KEY="sk-proj-openai-key" # only if using OpenAI